{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "California Census Data. Try to predict what class of income one has with the help of various features (job, gender, adress etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\florian\\.conda\\envs\\tfdl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\tfdl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\tfdl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\tfdl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\tfdl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\tfdl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# function to classify the income\n",
    "def func(num): \n",
    "    if num == ' <=50K': \n",
    "        return 0\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('census_data.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = dataset['income_bracket']\n",
    "new_income = income.apply(func) # Transform string to bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset\n",
    "newdataset = dataset.drop(['income_bracket'], axis=1)\n",
    "newdataset['income'] = new_income\n",
    "\n",
    "#Declare Features and Labes\n",
    "x_data = newdataset.drop('income',axis=1)\n",
    "labels = newdataset['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train test split 70/30\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, labels, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the feature columns to Tensorflow\n",
    "\n",
    "# Using hash buckets since idk the real lenghs\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass', hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education', hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status', hash_bucket_size=1000)\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country', hash_bucket_size=1000)\n",
    "\n",
    "# Using vocabulary list since I know the unique values \n",
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list('relationship',['Wife', 'Own-child', 'Husband', \n",
    "                                                                                         'Not-in-family', 'Other-relative', \n",
    "                                                                                         'Unmarried'])                                                                                     \n",
    "race = tf.feature_column.categorical_column_with_vocabulary_list('race', ['White', 'Asian-Pac-Islander','Amer-Indian-Eskimo',\n",
    "                                                                          'Other', 'Black'])\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list('gender', ['Female','Male'])\n",
    "\n",
    "# Using numeric column because these are continuus values\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week  = tf.feature_column.numeric_column('hours_per_week')\n",
    "\n",
    "# Combine all feature columns\n",
    "feat_cols = [workclass,education,marital_status,occupation,native_country,relationship, race,gender,age,education_num,\n",
    "            capital_gain,capital_loss,hours_per_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Florian\\AppData\\Local\\Temp\\tmp_uyzss63\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Florian\\\\AppData\\\\Local\\\\Temp\\\\tmp_uyzss63', '_session_config': None, '_save_checkpoints_secs': 600, '_tf_random_seed': 1, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Florian\\AppData\\Local\\Temp\\tmp_uyzss63\\model.ckpt.\n",
      "INFO:tensorflow:loss = 17.32868, step = 1\n",
      "INFO:tensorflow:global_step/sec: 376.503\n",
      "INFO:tensorflow:loss = 6.7214203, step = 101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.161\n",
      "INFO:tensorflow:loss = 25.03404, step = 201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.163\n",
      "INFO:tensorflow:loss = 92.927376, step = 301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.162\n",
      "INFO:tensorflow:loss = 9.239565, step = 401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.161\n",
      "INFO:tensorflow:loss = 256.33173, step = 501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.018\n",
      "INFO:tensorflow:loss = 19.824213, step = 601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.571\n",
      "INFO:tensorflow:loss = 7.4826403, step = 701 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.684\n",
      "INFO:tensorflow:loss = 6.0209236, step = 801 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.33\n",
      "INFO:tensorflow:loss = 41.8215, step = 901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.161\n",
      "INFO:tensorflow:loss = 12.629682, step = 1001 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.018\n",
      "INFO:tensorflow:loss = 45.856144, step = 1101 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.162\n",
      "INFO:tensorflow:loss = 37.722862, step = 1201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.857\n",
      "INFO:tensorflow:loss = 4.1095285, step = 1301 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.684\n",
      "INFO:tensorflow:loss = 9.740784, step = 1401 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.163\n",
      "INFO:tensorflow:loss = 7.2216363, step = 1501 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.57\n",
      "INFO:tensorflow:loss = 7.2481456, step = 1601 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.775\n",
      "INFO:tensorflow:loss = 87.0962, step = 1701 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.355\n",
      "INFO:tensorflow:loss = 212.35715, step = 1801 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.329\n",
      "INFO:tensorflow:loss = 4.4769735, step = 1901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.163\n",
      "INFO:tensorflow:loss = 15.432736, step = 2001 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.486\n",
      "INFO:tensorflow:loss = 28.530914, step = 2101 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.162\n",
      "INFO:tensorflow:loss = 43.60441, step = 2201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.686\n",
      "INFO:tensorflow:loss = 77.60303, step = 2301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.162\n",
      "INFO:tensorflow:loss = 7.185715, step = 2401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.33\n",
      "INFO:tensorflow:loss = 5.5083923, step = 2501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.685\n",
      "INFO:tensorflow:loss = 13.488987, step = 2601 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.327\n",
      "INFO:tensorflow:loss = 15.76094, step = 2701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.164\n",
      "INFO:tensorflow:loss = 10.024589, step = 2801 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.162\n",
      "INFO:tensorflow:loss = 47.250355, step = 2901 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.162\n",
      "INFO:tensorflow:loss = 59.91887, step = 3001 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.684\n",
      "INFO:tensorflow:loss = 10.112549, step = 3101 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.33\n",
      "INFO:tensorflow:loss = 7.482701, step = 3201 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.328\n",
      "INFO:tensorflow:loss = 76.49474, step = 3301 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.161\n",
      "INFO:tensorflow:loss = 29.52364, step = 3401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.33\n",
      "INFO:tensorflow:loss = 4.955748, step = 3501 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.33\n",
      "INFO:tensorflow:loss = 8.846011, step = 3601 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.327\n",
      "INFO:tensorflow:loss = 7.805591, step = 3701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.356\n",
      "INFO:tensorflow:loss = 57.451042, step = 3801 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.33\n",
      "INFO:tensorflow:loss = 24.802801, step = 3901 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.354\n",
      "INFO:tensorflow:loss = 24.874157, step = 4001 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.331\n",
      "INFO:tensorflow:loss = 159.40936, step = 4101 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.017\n",
      "INFO:tensorflow:loss = 15.763622, step = 4201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.327\n",
      "INFO:tensorflow:loss = 104.804825, step = 4301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.163\n",
      "INFO:tensorflow:loss = 34.676765, step = 4401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.684\n",
      "INFO:tensorflow:loss = 3.7555099, step = 4501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.33\n",
      "INFO:tensorflow:loss = 9.103962, step = 4601 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.162\n",
      "INFO:tensorflow:loss = 7.4415517, step = 4701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.685\n",
      "INFO:tensorflow:loss = 16.976555, step = 4801 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.163\n",
      "INFO:tensorflow:loss = 28.96675, step = 4901 (0.219 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\Florian\\AppData\\Local\\Temp\\tmp_uyzss63\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10.7838545.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x2052914c048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input function\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x = x_train,y= y_train, batch_size=25, num_epochs=None,shuffle=True)\n",
    "\n",
    "# Set up linear classifier model and train\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols)\n",
    "model.train(input_fn = input_func, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Florian\\AppData\\Local\\Temp\\tmp_uyzss63\\model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "# Set up an prediction input func  for the test data\n",
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x = x_test, batch_size=len(x_test), shuffle=False)\n",
    "predictions_gen = model.predict(input_fn=pred_input_func) # Returns a generator \n",
    "\n",
    "# Get prediciton list\n",
    "predictions = list(predictions_gen)\n",
    "\n",
    "# Only get the predicted label values for calculating the model score\n",
    "final_preds = [pred['class_ids'][0] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      7424\n",
      "           1       0.67      0.62      0.65      2345\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.78      0.76      0.77      9769\n",
      "weighted avg       0.83      0.84      0.83      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, y_pred=final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
