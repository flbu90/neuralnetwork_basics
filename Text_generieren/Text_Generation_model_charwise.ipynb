{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with the book \"verwandlung\" von Franz Kafka\n",
    "# Book pages from 60-1952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\florian\\.conda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\florian\\.conda\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verwandlung.txt', encoding=\"utf_8\", mode='r') as file: # make sure its utf_8 encoding for german texts\n",
    "    contents = file.read()\n",
    "    \n",
    "full_text = \"\\n\".join(contents.split(\"\\n\")[59:1952])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore the dataset\n",
    "\n",
    "# len(contents.split(\"\\n\")[59:1952]) # Split at end of each line\n",
    "# contents.split(\"\\n\")[59:1952] # Every line is an element in this list\n",
    "\n",
    "full_text = \"\\n\".join(contents.split(\"\\n\")[59:1952]) # join all lines to get the complete text\n",
    "\n",
    "# len(set(full_text)) # How many different chars are in full text set() sth like unique\n",
    "\n",
    "unique_chars = set(full_text)\n",
    "\n",
    "# enumerate(unique_chars) # returns a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping\n",
    "int_to_char = {}\n",
    "char_to_int = {}\n",
    "\n",
    "for i,j in enumerate(unique_chars):\n",
    "    int_to_char[i] = j\n",
    "    char_to_int[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 45, 52, 25, 66, 49, 9, 28, 2, 49, 25, 29, 48, 61, 52, 48, 25, 9, 13, 0, 9, 52, 25, 10, 2, 49, 28, 9, 0, 52, 25, 48, 20, 52, 25, 20, 0, 49, 20, 24], [45, 52, 25, 66, 49, 9, 28, 2, 49, 25, 29, 48, 61, 52, 48, 25, 9, 13, 0, 9, 52, 25, 10, 2, 49, 28, 9, 0, 52, 25, 48, 20, 52, 25, 20, 0, 49, 20, 24, 13], [52, 25, 66, 49, 9, 28, 2, 49, 25, 29, 48, 61, 52, 48, 25, 9, 13, 0, 9, 52, 25, 10, 2, 49, 28, 9, 0, 52, 25, 48, 20, 52, 25, 20, 0, 49, 20, 24, 13, 28], [25, 66, 49, 9, 28, 2, 49, 25, 29, 48, 61, 52, 48, 25, 9, 13, 0, 9, 52, 25, 10, 2, 49, 28, 9, 0, 52, 25, 48, 20, 52, 25, 20, 0, 49, 20, 24, 13, 28, 9]]\n",
      "[13, 28, 9, 0]\n"
     ]
    }
   ],
   "source": [
    "length = 40 # Counter Var for taking 40 chars into account\n",
    "\n",
    "# Create Placeholders\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(full_text) - length): # - lenght prevents the loop to go over the last char\n",
    "    \n",
    "    line = full_text[i:i+length] # gets the first 40 chars\n",
    "    X.append([char_to_int[c] for c in line])  # Since chars/strings are no use to our NN we must convert them to ints\n",
    "    y.append(char_to_int[full_text[i+length]])\n",
    "\n",
    "\"\"\"\n",
    "# What happens in the for loop: \n",
    "line =  \"Als Gregor Samsa eines Morgens aus unruh\"\n",
    "int_line = [char_to_int[c] for c in line]\n",
    "\n",
    "print(char_to_int['A'])\n",
    "print(char_to_int['l'])\n",
    "print(char_to_int['s'])\n",
    "\n",
    "print(int_line)\n",
    "\"\"\"\n",
    "\n",
    "print(X[:4])\n",
    "print(y[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for input with on hot encoding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X = to_categorical(X, num_classes = len(unique_chars))\n",
    "y = to_categorical(y, num_classes = len(unique_chars)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121090, 40, 68)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mode\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(40,68)))\n",
    "model.add(Dense(68, activation=\"softmax\")) # We have 68 different chars\n",
    "          \n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "save_model = ModelCheckpoint(\"weigts.{epoch:02d}-{loss:.2f}.hdf5\") # Saves the model after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121090/121090 [==============================] - 144s 1ms/step - loss: 2.3638\n",
      "Epoch 2/3\n",
      "121090/121090 [==============================] - 141s 1ms/step - loss: 1.9279\n",
      "Epoch 3/3\n",
      "121090/121090 [==============================] - 138s 1ms/step - loss: 1.7858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28fa8e3d828>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, batch_size=32, epochs=3, callbacks=[save_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need the mapping informations to use the model on different data\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"int_to_char.pickle\",\"wb\") as file: \n",
    "    pickle.dump(int_to_char,file)\n",
    "\n",
    "with open(\"char_to_int.pickle\",\"wb\") as file: \n",
    "    pickle.dump(char_to_int,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
